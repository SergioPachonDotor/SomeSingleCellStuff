# GeneXOmics Sequencing Data Processing Pipeline


## Pipeline Overview

The pipeline consists of the following steps:

1. **Data Simulation**: Generates synthetic single-cell RNA-seq data using Python scripts.
2. **Genome Indexing**: Creates a STAR genome index for the alignment process.
3. **Read Alignment**: Aligns the simulated reads to the reference genome using STAR.
4. **BAM Filtering**: Filters aligned reads to remove low-quality sequences using SAMtools.
5. **Deduplication**: Deduplicates UMIs using UMI-tools to remove PCR duplicates.

## Installation

### Prerequisites

This pipeline relies on several tools and packages that need to be installed using `conda`, a package manager that allows you to create isolated environments for your software.

1. **Install Miniconda** (if not already installed):
   - Follow the instructions on [Miniconda Installation](https://docs.conda.io/en/latest/miniconda.html).

2. **Create and activate a conda environment**:
   ```bash
   conda create -n genomics-pipeline python=3.10 -y
   conda activate genomics-pipeline
   ```

3. **Install dependencies using conda**:
   ```bash
   conda install -c bioconda snakemake star samtools umi-tools
   ```

4. **Install additional Python packages** (if required by the simulation scripts):
   ```bash
   pip install -r requirements.txt
   ```

## Usage

### Running the Pipeline

1. **Clone the repository**:
   ```bash
   git clone <repository_url>
   cd <repository_directory>
   ```

2. **Activate the conda environment**:
   ```bash
   conda activate genomics-pipeline
   ```

3. **Run the Snakemake pipeline**:
   ```bash
   snakemake --cores 8
   ```

   Adjust the `--cores` parameter based on your system's available resources.

### Example Input and Output

#### Input

- Simulated FASTQ files generated by `simulate_data`.
- Reference genome and annotations located in the `reference_genome` directory.

#### Output

- Deduplicated BAM files located in `output/second_analysis/{sample}/deduplicated.bam` for each sample.

## Pipeline Steps Explained

### 1. Simulate Data

**Description**: Simulates single-cell RNA-seq data using custom Python scripts. This step generates FASTQ files and prepares the necessary output directories.

**Execution**:
```bash
python3 ./scripts/01_single_cell_data_simulator.py \
    --genome_dir ./reference_genome \
    --samples_dir ./samples \
    --genome_size_bp 5000000 \
    --num_of_samples 3

python3 ./scripts/02_output_dirs_creator.py \
    --samples_dir ./samples \
    --output_dir ./output
```

### 2. Genome Indexing

**Description**: STAR generates a genome index from the simulated reference genome, which is used in the alignment step.

**Execution**:
```bash
STAR --runThreadN 8 \
     --runMode genomeGenerate \
     --genomeDir ./reference_genome/ \
     --genomeFastaFiles ./reference_genome/simulated_genome.fa \
     --sjdbGTFfile ./reference_genome/simulated_genes.gtf \
     --genomeSAindexNbases 10
```

### 3. Align Reads

**Description**: Aligns the simulated reads to the reference genome using STAR, processing each tissue sample independently.

**Execution**:
```bash
STAR --genomeDir ./reference_genome/ \
     --readFilesIn samples/{sample}/sample_test_1_{sample}_L001_R1_001.fastq.gz samples/{sample}/sample_test_1_{sample}_L001_R2_001.fastq.gz \
     --readFilesCommand zcat \
     --outFileNamePrefix output/first_analysis/{sample}/STAR_output_ \
     --runThreadN 8 \
     --soloType Droplet \
     --soloCBwhitelist samples/{sample}/whitelist_sample_test_1_{sample}.txt \
     --soloCBlen 10 \
     --soloUMIlen 8 \
     --outSAMtype BAM SortedByCoordinate \
     --outSAMattributes NH HI AS nM CR UR \
     --soloFeatures Gene
```

### 4. Filter BAM Files

**Description**: Filters aligned BAM files to retain high-quality alignments using SAMtools.

**Execution**:
```bash
samtools view -b -F 4 -q 20 output/first_analysis/{sample}/STAR_output_Aligned.sortedByCoord.out.bam > output/first_analysis/{sample}/filtered.bam
samtools index output/first_analysis/{sample}/filtered.bam
```

### 5. Deduplication

**Description**: Deduplicates UMIs to remove PCR duplicates using UMI-tools.

**Execution**:
```bash
umi_tools dedup -I output/first_analysis/{sample}/filtered.bam -S output/second_analysis/{sample}/deduplicated.bam --output-stats=output/second_analysis/{sample}/dedup_stats
```

## Configuration

### Modifying Sample Inputs

- To add or modify samples, update the `SAMPLES` list in the Snakefile:
  ```python
  SAMPLES = ["tissue1", "tissue2", "tissue3"]
  ```
- Ensure each sample follows the correct input naming convention (`sample_test_1_{sample}_L001_R1_001.fastq.gz`).

## Troubleshooting

- **Missing Dependencies**: Verify that all required software is installed in the conda environment.
- **Memory/CPU Limitations**: Adjust the number of threads (`--cores`) based on your system resources.
- **Pipeline Errors**: Run Snakemake with `--printshellcmds` to debug any errors encountered during execution.

## Contact

For assistance, please contact Sergio Pachon at sap9827@gmail.com.